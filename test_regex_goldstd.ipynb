{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from myparser import Parser\n",
    "from random import choice\n",
    "import string\n",
    "# import nltk\n",
    "import re\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"is.*(?=\\s\\bof\\s)\"\n",
    "# relations_list = [\"is a\", \"is the\", \"are\", \"is an\", \"was the\", \"were\", \"was a\", \"was an\"]\n",
    "# relation_patterns = [r\"(?<=\\b%s\\s)((\\w*)(?:\\s*))*\" % rel for rel in relations_list]\n",
    "# relations_re = re.compile('|'.join(relation_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b(is|mean)\b\\s+(\b(the|a|an)\b\\s+)?(\\w+\\s+)*(?P<type>\\w+)(\\s+\b(from|in|of|that|for)\b)\n",
      "\\b(is|mean)\\b\\s+(\\b(the|a|an)\\b\\s+)?(\\w+\\s+)*(?P<type>\\w+)(\\s+\\b(from|in|of|that|for)\\b)\n",
      "<_sre.SRE_Match object; span=(24, 50), match='is the political leader of'>\n",
      "leader\n"
     ]
    }
   ],
   "source": [
    "complete_pat = r\" \\b(and other|for a|(is|are|was|were|will be|to be)\\s(the\\s((kind(s)?|part(s)?|f\" + \\\n",
    "r\"orm(s)?|sort(s)?|type(s)?|set(s)?|range(s)?|body(s)?|style(s)?)\\sof)?|an\\s((kind\" + \\\n",
    "r\"(s)?|part(s)?|form(s)?|sort(s)?|type(s)?|set(s)?|range(s)?|body(s)?|style(s)?)\\s\" + \\\n",
    "r\"of)?|a\\s((kind(s)?|part(s)?|form(s)?|sort(s)?|type(s)?|set(s)?|range(s)?|body(s)\" + \\\n",
    "r\"?|style(s)?)\\sof)?|some\\s((kind(s)?|part(s)?|form(s)?|sort(s)?|type(s)?|set(s)?|\" + \\\n",
    "r\"range(s)?|body(s)?|style(s)?)\\sof)?|one\\s((kind(s)?|part(s)?|form(s)?|sort(s)?|t\" + \\\n",
    "r\"ype(s)?|set(s)?|range(s)?|body(s)?|style(s)?)\\sof)?)?)\\b\\s?([ \\w\\_\\-\\&\\s\\\"]+?)\\s\" + \\\n",
    "r\"?\\b(\\.|\\,|(or|and|by|that|around|of|on|from|at|in|with|who|where|what|whose|whic\" + \\\n",
    "r\"h|made|done|written|[a-z]*ed)\\b)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46850"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda val: val!=\"\", types.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.09%\n"
     ]
    }
   ],
   "source": [
    "verbs = [\"is\", \"are\", \"mean\", \"means\", \"was\", \"were\", \"will be\", \"to be\"]\n",
    "dets = [\"the\", \"a\", \"an\", \"The\"]\n",
    "previous_noun = [\"part(s)?\", \"type(s)?\", \"one(s)?\", \"style(s)?\", \"word(s)?\", \"set(s)?\"]\n",
    "end_wds = [\"from\", \"in\", \"of\", \"that\", \"for\", \"with\", \"and\", \"around\",\n",
    "           \"or\", \"on\", \"who\", \"where\", \"what\", \"which\", \"at\", \"by\", \"[a-z]+ed\", \"made\"]\n",
    "\n",
    "end_pat = r\"\\b(\\.|\\,|(\" + r\"|\".join(end_wds) + r\")\\b)\"\n",
    "type_pat = r\"(?P<type>[ \\w\\_\\-\\&\\s\\\"]+?)\\s?\"\n",
    "\n",
    "complete_pat = r\"\\b(\" + r\"|\".join(verbs) + r\")\\s+(((\" + r\"|\".join(dets) + r\")\\s+)?(\\w+\\s+)*(\" + \\\n",
    "                r\"|\".join(previous_noun) + r\")\\s+(of|for)\\s+)?((\" + r\"|\".join(dets) + r\")\\s+)?\" + type_pat + end_pat\n",
    "\n",
    "global relations_re\n",
    "relations_re = re.compile(complete_pat)\n",
    "types = {}\n",
    "for page in Parser('./wikipedia-first.txt'):\n",
    "    types[page.title] = extractType(page)\n",
    "scores = eval_acc_goldstd(types)\n",
    "# print(debug_goldstd(types))\n",
    "print(\"{0:.2%}\".format(scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractType(page):\n",
    "\n",
    "    matching = relations_re.search(page.content)\n",
    "    if matching:\n",
    "        typ = matching.group(\"type\")\n",
    "        return typ.split()[-1].strip()\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_acc_goldstd(predicted_fact):\n",
    "\n",
    "    with open('./gold-standard-sample.tsv', mode='r', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        goldstd = {rows[0]:rows[1] for rows in reader}\n",
    "\n",
    "    scores = list(map(lambda ent: goldstd[ent] == predicted_fact[ent],\n",
    "                        goldstd.keys()))\n",
    "\n",
    "    non_empty = list(map(lambda ent: predicted_fact[ent] != \"\",\n",
    "                        goldstd.keys()))\n",
    "\n",
    "    precision = float(sum(scores)) / sum(non_empty)\n",
    "    rappel = float(sum(scores)) / len(scores)\n",
    "    \n",
    "    return precision, rappel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_goldstd(predicted_fact):\n",
    "\n",
    "    with open('./gold-standard-sample.tsv', mode='r', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        goldstd = {rows[0]:rows[1] for rows in reader}\n",
    "\n",
    "    scores = []\n",
    "    with open('./results_on_goldstd.tsv', 'w', encoding=\"utf-8\") as test:\n",
    "        for ent in goldstd.keys():\n",
    "            if goldstd[ent]==predicted_fact[ent]:\n",
    "                scores.append(True)\n",
    "            else:\n",
    "                scores.append(False)\n",
    "                test.write(ent + \"\\t\" + goldstd[ent] + \"\\t\" + predicted_fact[ent] + \"\\n\")\n",
    "    \n",
    "    return float(sum(scores)) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24444444444444444\n"
     ]
    }
   ],
   "source": [
    "verbs = [\"is\", \"are\", \"mean\", \"means\", \"was\", \"were\"]\n",
    "dets = [\"the\", \"a\", \"an\"]\n",
    "previous_noun = [\"part\", \"type\", \"one\", \"style\"]\n",
    "end_wds = [\"from\", \"in\", \"of\", \"that\", \"for\", \"with\", \"and\", \"around\"]\n",
    "complete_pat = []\n",
    "# \\w+ => \\w+(\\'|\\-)?\\w*\n",
    "# r\"(?P<type>\\w+)\" --> r\"([\\w\\_\\-\\&\\s\\\"]+?)\\s?\"\n",
    "complete_pat.append(r\"\\b(\" + r\"|\".join(verbs) + r\")\\b\\s+(\\b(\" + r\"|\".join(dets) + \\\n",
    "                      r\")\\b\\s+)?(\\b(\"+ \"|\".join(previous_noun) + r\")\\b\\s+\\bof\\b\\s+)+(\\b(\" + r\"|\".join(dets) + \\\n",
    "                      r\")\\b\\s+)?(\\w+\\s+)*?(?P<type>[\\w\\_\\-\\&\\s\\\"]+?)((\\s+\\b\\w+ed\\b)?\\s+\\b(\" + r\"|\".join(end_wds) + r\")\\b)(\\s+\\w+)*\\.$\")\n",
    "complete_pat.append(r\"\\b(\" + r\"|\".join(verbs) + r\")\\b\\s+(\\b(\" + r\"|\".join(dets) + \\\n",
    "                          r\")\\b\\s+)?(\\w+\\s+)*?(?P<type>[\\w\\_\\-\\&\\s\\\"]+?)((\\s+\\b\\w+ed\\b)?\\s+\\b(\" + r\"|\".join(end_wds) + r\")\\b)\")\n",
    "complete_pat.append(r\"\\b(\" + r\"|\".join(verbs) + r\")\\b\\s+(\\b(\" + r\"|\".join(dets) + r\")\\b\\s+)?(\\w+\\s+)*(?P<type>[\\w\\_\\-\\&\\s\\\"]+?)\")\n",
    "relations_re = []\n",
    "for complete_re in complete_pat:\n",
    "    relations_re.append(re.compile(complete_re))\n",
    "types = {}\n",
    "for page in Parser('./wikipedia-first.txt'):\n",
    "    types[page.title] = extractType(page, relations_re)\n",
    "# scores = eval_acc_goldstd(types)\n",
    "print(debug_goldstd(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
